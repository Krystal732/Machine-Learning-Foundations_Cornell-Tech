{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Building Gradient Boosted Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this exercise, will you will train two gradient boosted decision trees and compare their performances. \n",
        "\n",
        "**<font color='red'>Note: Some of the code cells in this notebook may take a while to run.</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Packages\n",
        "\n",
        "Before you get started, import a few packages. Run the code cell below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will also import the scikit-learn `GradientBoostingClassifier`, the `train_test_split()` function for splitting the data into training and test sets, and the functions `roc_curve` and `auc` to evaluate the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Step 1: Load a 'ready-to-fit' Data Set \n",
        "\n",
        "We will work with the \"cell2celltrain\" data set. This data set is already preprocessed, with the proper formatting, outliers, and missing values taken care of, and all numerical columns scaled to the [0, 1] interval. One-hot encoding has been performed on all categorical columns. Run the cell below to load the data set and save it to DataFrame `df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = os.path.join(os.getcwd(), \"data\", \"cell2celltrain.csv\")\n",
        "df = pd.read_csv(filename, header=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create Training and Test Data Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### a. Create Labeled Examples\n",
        "\n",
        "Let's obtain columns from our data set to create labeled examples. \n",
        "In the code cell below, carry out the following steps:\n",
        "\n",
        "* Get the `Churn` column from DataFrame `df` and assign it to the variable `y`. This will be our label.\n",
        "* Assign all other columns from DataFrame `df` to the variable `X`. These will be our features. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df['Churn'] \n",
        "X = df.drop(columns = 'Churn', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### b. Split Labeled Examples Into Training and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Fit Two Gradient Boosted Decision Tree (GBDT) Classifiers\n",
        "\n",
        "A gradient boosted decision tree can be thought of as a sequence of individual decision trees that further refine the model's output prediction at each step. The power of GBDTs is in how they learn and weigh these trees in such a way that they can approximate a wide variety of non-linear functions between inputs $X$ and outputs $Y$. \n",
        "</p>\n",
        "\n",
        "We will use the scikit-learn's `GradientBoostingClassifier`. Please refer to the online [documentation](http://scikit-learn.org/stable/modules/ensemble.html) for a brief overview of scikit-learn's ensemble methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the code cell below, build and train two GBDT models, one with a max depth of 2 and the other with a max depth of 10.\n",
        "\n",
        "1. Use ```GradientBoostingClassifier()``` to create a model object, and assign the result to the variable ```gbdt_2_model```. You will provide the following arguments: <b>n_estimators = 50, max_depth = 2</b>.\n",
        "\n",
        "2. Fit ```gbdt_2_model``` to the training data.\n",
        "\n",
        "3. Use the ```model.predict_proba()``` method  to use the fitted model to predict values for the test data. The method will return two columns. Store the values of the *second* column to a list called ```gbdt_2_predictions```. \n",
        "\n",
        "4. Use ```GradientBoostingClassifier()``` to create a model object, and assign the result to the variable ```gbdt_10_model```. You will provide the following arguments: <b>n_estimators = 50, max_depth = 10</b>.\n",
        "\n",
        "5. Fit ```gbdt_10_model``` to the training data.\n",
        "\n",
        "6. Use the ```model.predict_proba()``` method  to use the fitted model to predict values for the test data. The method will return two columns. Store the values of the *second* column to a list called ```gbdt_10_predictions```.\n",
        "\n",
        "\n",
        "<b>Note:</b> You can expect this to take several minutes to run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Graded Cell\n",
        "\n",
        "The cell below will be graded. Remove the line \"raise NotImplementedError()\" before writing your code. Note: This may take a few minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "4c149f21723dcc1f2d7c4b35834eef61",
          "grade": false,
          "grade_id": "cell-rf",
          "locked": false,
          "schema_version": 1,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "print('Begin GBDT Implementation...')\n",
        "# 1. Create the GradientBoostingClassifier model object below and assign to variable 'gbdt_2_model'\n",
        "\n",
        "# YOUR CODE HERE\n",
        "gbdt_2_model = GradientBoostingClassifier(n_estimators = 50, max_depth = 2)\n",
        "\n",
        "# 2. Fit the model to the training data below\n",
        "\n",
        "# YOUR CODE HERE\n",
        "gbdt_2_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Make predictions on the test data using the predict_proba() method and assign the result to the \n",
        "# variable 'gbdt_2_predictions' below\n",
        "\n",
        "# YOUR CODE HERE\n",
        "gbdt_2_predictions = list(gbdt_2_model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "# 4. Create the GradientBoostingClassifier model object below and assign to variable 'gbdt_10_model'\n",
        "\n",
        "# YOUR CODE HERE\n",
        "gbdt_10_model = GradientBoostingClassifier(n_estimators = 50, max_depth = 10)\n",
        "\n",
        "# 5. Fit the model to the training data below\n",
        "\n",
        "# YOUR CODE HERE\n",
        "gbdt_10_model.fit(X_train, y_train)\n",
        "\n",
        "# 6. Make predictions on the test data using the predict_proba() method and assign the result to the \n",
        "# variable 'gbdt_10_predictions' below\n",
        "\n",
        "# YOUR CODE HERE\n",
        "gbdt_10_predictions = list(gbdt_10_model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "print('End')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Self-Check\n",
        "\n",
        "Run the cell below to test the correctness of your code above before submitting for grading. Do not add code or delete code in the cell. Note: This may take a few minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "65f90654213cf8d9d296ab5c3d9edeeb",
          "grade": true,
          "grade_id": "cell-rf-test",
          "locked": true,
          "points": 3,
          "schema_version": 1,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "# Run this self-test cell to check your code; \n",
        "# do not add code or delete code in this cell\n",
        "from jn import testGBDTModel\n",
        "\n",
        "try:\n",
        "    p, err = testGBDTModel(df, gbdt_2_model, gbdt_10_model, gbdt_2_predictions, gbdt_10_predictions)\n",
        "    print(err)\n",
        "except Exception as e:\n",
        "    print(\"Error!\\n\" + str(e))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Evaluate the Performance Using ROC and AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will now plot two ROC curves for the two GBDT classifiers on the same graph. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the code cell below, use the `roc_curve()` function to record the true positive and false positive rates for both models. \n",
        "\n",
        "1. Call `roc_curve()` with arguments `y_test` and `gbdt_2_predictions`. The `roc_curve` function produces three outputs. Save the three items to the following variables, respectively: `fpr_2`, `tpr_2`, and `thresholds_2`.\n",
        "\n",
        "2. Call `roc_curve()` with arguments `y_test` and `gbdt_10_predictions`. Save the three items to the following variables, respectively: `fpr_10`, `tpr_10`, and `thresholds_10`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Graded Cell\n",
        "\n",
        "The cell below will be graded. Remove the line \"raise NotImplementedError()\" before writing your code. Note: This may take a few minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "bca1f543c2717e38b6dad00d20e22abd",
          "grade": false,
          "grade_id": "cell-roc",
          "locked": false,
          "schema_version": 1,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "print('Computing ROC Curve...')\n",
        "\n",
        "#1. Use roc_curve to record fpr and tpr for gbdt_2_model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "fpr_2, tpr_2, thresholds_2 = roc_curve(y_test, gbdt_2_predictions)\n",
        "\n",
        "#2. Use roc_curve to record fpr and tpr for gbdt_10_model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "fpr_10, tpr_10, thresholds_10 = roc_curve(y_test, gbdt_10_predictions)\n",
        "\n",
        "print('End')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Self-Check\n",
        "\n",
        "Run the cell below to test the correctness of your code above before submitting for grading. Do not add code or delete code in the cell. Note: This may take a few minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "27e7731e634445a5e94d7025f122f558",
          "grade": true,
          "grade_id": "cell-roc-test",
          "locked": true,
          "points": 2,
          "schema_version": 1,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "# Run this self-test cell to check your code; \n",
        "# do not add code or delete code in this cell\n",
        "from jn import testROC\n",
        "\n",
        "try:\n",
        "    p, err = testROC(df, gbdt_2_model, gbdt_10_model, gbdt_2_predictions, gbdt_10_predictions,\n",
        "                fpr_2, tpr_2,fpr_10, tpr_10)\n",
        "    print(err)\n",
        "except Exception as e:\n",
        "    print(\"Error!\\n\" + str(e))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The code cell below plots the ROC curves for both models. Run the code cell and inspect the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Plotting ROC Curve...')\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "\n",
        "sns.lineplot(x=fpr_2, y=tpr_2, marker = 'o')\n",
        "sns.lineplot(x=fpr_10, y=tpr_10, marker = 'o')\n",
        "\n",
        "plt.title(\"Receiver operating characteristic (ROC) curve\")\n",
        "plt.xlabel(\"False positive rate\")\n",
        "plt.ylabel(\"True positive rate\")\n",
        "plt.legend(['GBDT with max_depth=2', 'GBDT with max_depth=10'])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the code cell below, use the `auc()` function to compute the areas under each of the receiver operating characteristic (ROC) curves. \n",
        "\n",
        "For each model, call the function with the `fpr` argument first and the `tpr` argument second. \n",
        "Save the results to variables `auc_2` and `auc_10`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Graded Cell\n",
        "\n",
        "The cell below will be graded. Remove the line \"raise NotImplementedError()\" before writing your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "900234309be6875f11cd773e6a4f5a21",
          "grade": false,
          "grade_id": "cell-auc",
          "locked": false,
          "schema_version": 1,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "#1. AUC for gbdt_2_model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "auc_2 = auc(fpr_2, tpr_2)\n",
        "\n",
        "print(\"AUC of the GBDT model with a max depth of 2 is {:.3f}\".format(auc_2))\n",
        "\n",
        "# 2. AUC for gbdt_10_model\n",
        "\n",
        "# YOUR CODE HERE\n",
        "auc_10 = auc(fpr_10, tpr_10)\n",
        "\n",
        "print(\"AUC of the GBDT model with a max depth of 10 is {:.3f}\".format(auc_10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Self-Check\n",
        "\n",
        "Run the cell below to test the correctness of your code above before submitting for grading. Do not add code or delete code in the cell. Note: This may take a few minutes to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "671b06661d630fc7e4b1354f2afcc371",
          "grade": true,
          "grade_id": "cell-auc-test",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        }
      },
      "outputs": [],
      "source": [
        "# Run this self-test cell to check your code; \n",
        "# do not add code or delete code in this cell\n",
        "from jn import testROC\n",
        "\n",
        "try:\n",
        "    p, err = testROC(df, gbdt_2_model, gbdt_10_model, gbdt_2_predictions, gbdt_10_predictions,\n",
        "                fpr_2, tpr_2,fpr_10, tpr_10, [auc_2, auc_10])\n",
        "    print(err)\n",
        "except Exception as e:\n",
        "    print(\"Error!\\n\" + str(e))\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}